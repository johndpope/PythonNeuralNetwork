{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Neural Networks\n",
    "Welcome! I'm still moving forward in learning the important parts of data science, machine learning and artificial intelligence. This time I'll be exploring how simple [neural networks](https://en.wikipedia.org/wiki/Artificial_neural_network) are actually _designed from scratch_.\n",
    "\n",
    "This notebook will be exploring the mathematical theory behind neural networks in order to better understand how they work and why they might fail. I am a firm believer that you should learn the stuff you're working with on a theoretical level. That way, if there is any odd behaviour, you can confirm what might be causing it. I'm not a code-monkey: I'm a human who can think.\n",
    "\n",
    "## Neural Networks\n",
    "Let's start by defining what a neural network, and eventually an artificial neural network, is. A neural network is defined as, \"a series of interconnected neurons whose activation defines a recognizable linear pathway.\" To take that out of nerd speak and return it back to human speak, a neural network is a brain! It is a bunch of neurons that fire depending on inputs to produce outputs.\n",
    "\n",
    "An _artificial_ neural network is simply a digitized version of this. By creating a set of connected artificial neurons, it is possible to predict non-linear behaviour from lots of different input types. Although the principle is quite organic, we use massive amounts of mathematics to develop our neural networks. You'll get a taste of that as you progress throughout this notebook.\n",
    "\n",
    "## Why Not Use A Package Like scikit-learn?\n",
    "My background is in physics. We want to understand the deep relationships and theory behind everything in order to predict, debug and analyse results. Machine learning is a prime example of something that should be understood in theory. \n",
    "\n",
    "By understanding _how_ AI works, you can begin to predict downfalls in your training models. You might understand why two neurons keep getting the same weights. You can understand the significance of an outlying result. \n",
    "\n",
    "If I were to just use a machine learning package like scikit-learn, Tensorflow, Caffe or the likes I would never understand what I'm doing. Data would pass in and magic would pass out. That's not a good thing. So I've decided that I should implement a very basic neural network to get the proper understanding I require to move forward.\n",
    "\n",
    "## Inspiration, Tutorials and Resources\n",
    "Of course I never learnt this stuff from trial and error. I had to teach myself using a bunch of resources online, who I wouldn't want to go unacknowledged. The main resources I used were:\n",
    " - iamtrask's blog article on \"[A Neural Network in 11 lines of Python](https://iamtrask.github.io/2015/07/12/basic-python-network/)\"\n",
    " - Matt Mazur's fantastic article on the theory behind backpropogation, \"[A Step by Step Backpropagation Example](https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/)\" \n",
    " - A short (25 minute) video on deep neural networks that is both interesting and informative by Brandon Rohrer, \"[How Deep Neural Networks Work](https://www.youtube.com/watch?v=ILsA4nyG7I0)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# The Problem To Solve\n",
    "I've noticed that there is a \"Hello World\" problem for neural networks: the XOR gate! It doesn't follow and exact 1-to-1 relationship so it is a nice and simple problem to try to solve. For anyone reading this who doesn't know what an XOR gate it, it is simply:\n",
    "\n",
    "> XOR(A, B) = (A OR B) AND (NOT (A AND B)) \n",
    "\n",
    "I know that looks complicated, but it really isn't. Simply put, it returns true if any of the inputs are true _except_ when all are true. It's a great example to work with because of that last clause.\n",
    "\n",
    "If that isn't particularly clear, I've designed a circuit diagram of the operation for you to look at below. Note that I forgot to include a not \"bubble\" on the first AND gate.\n",
    "\n",
    "<div style='margin: 100px'>\n",
    "![XOR Gate Circuit](imgs/neuralnetworkcircuit.png)\n",
    "<p style='text-align: center'><i>Figure 1: The Circuit Diagram of an XOR Gate. Created in draw.io.</i></p>\n",
    "</div>\n",
    "\n",
    "# The Neural Network\n",
    "The neural network I'll be designing will be super simple: 2 inputs, 2 hidden neurons in a single hidden layer and a single output neuron. That means that there will be 6 weighted synapses in total. \n",
    "\n",
    "There is a reason for this design. I'm treating each neuron and an \"operation\" in a Boolean Algebra question. So one neuron can calculate the OR's and another could calculate the AND's. From my experience, I know the minimum amount of basic circuitry needed to design one: a single OR and a single AND gate. Thus we will need at least two hidden neurons to compute these operations and a single output neuron to do the final AND operation.\n",
    "\n",
    "I've also decided to show a visualisation of the neural network I'll be designing. Each node and synapse has a label associated with it that I'll be using throughout this notebook.\n",
    "\n",
    "<div style='margin: 100px'>\n",
    "![Neural Network](imgs/neuralnetworkdiagram.png)\n",
    "<p style='text-align: center'><i>Figure 1: The Neural Network. Created in draw.io.</i></p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
